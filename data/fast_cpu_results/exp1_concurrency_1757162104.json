{
  "traces": [
    {
      "request_id": 0,
      "seq_prompt": 129,
      "seq_generate": 32,
      "total_latency_s": 37.21695303916931,
      "tokens_per_s": 0.8598232092326665,
      "peak_alloc_bytes": 0,
      "peak_reserved_bytes": 0,
      "backend": "huggingface",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "timestamp": 1757162106.3330662,
      "error": null
    },
    {
      "request_id": 0,
      "seq_prompt": 129,
      "seq_generate": 32,
      "total_latency_s": 40.68078398704529,
      "tokens_per_s": 0.7866121756697299,
      "peak_alloc_bytes": 0,
      "peak_reserved_bytes": 0,
      "backend": "huggingface",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "timestamp": 1757162143.553735,
      "error": null
    },
    {
      "request_id": 1,
      "seq_prompt": 129,
      "seq_generate": 32,
      "total_latency_s": 41.833906412124634,
      "tokens_per_s": 0.7649297601986677,
      "peak_alloc_bytes": 0,
      "peak_reserved_bytes": 0,
      "backend": "huggingface",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "timestamp": 1757162184.2348068,
      "error": null
    },
    {
      "request_id": 0,
      "seq_prompt": 129,
      "seq_generate": 32,
      "total_latency_s": 37.72590756416321,
      "tokens_per_s": 0.8482234640896382,
      "peak_alloc_bytes": 0,
      "peak_reserved_bytes": 0,
      "backend": "huggingface",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "timestamp": 1757162226.0704985,
      "error": null
    },
    {
      "request_id": 1,
      "seq_prompt": 129,
      "seq_generate": 32,
      "total_latency_s": 37.47281265258789,
      "tokens_per_s": 0.8539524453814935,
      "peak_alloc_bytes": 0,
      "peak_reserved_bytes": 0,
      "backend": "huggingface",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "timestamp": 1757162263.8026018,
      "error": null
    },
    {
      "request_id": 2,
      "seq_prompt": 129,
      "seq_generate": 32,
      "total_latency_s": 41.33313727378845,
      "tokens_per_s": 0.7741972206956791,
      "peak_alloc_bytes": 0,
      "peak_reserved_bytes": 0,
      "backend": "huggingface",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "timestamp": 1757162301.2756555,
      "error": null
    },
    {
      "request_id": 3,
      "seq_prompt": 129,
      "seq_generate": 32,
      "total_latency_s": 41.23772192001343,
      "tokens_per_s": 0.7759885490781635,
      "peak_alloc_bytes": 0,
      "peak_reserved_bytes": 0,
      "backend": "huggingface",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "timestamp": 1757162342.6090686,
      "error": null
    }
  ],
  "metrics": {
    "total_requests": 7,
    "successful_requests": 7,
    "failed_requests": 0,
    "error_rate": 0.0,
    "mean_latency_s": 39.64303183555603,
    "min_latency_s": 37.21695303916931,
    "max_latency_s": 41.833906412124634,
    "p50_latency_s": 40.68078398704529,
    "p95_latency_s": 41.833906412124634,
    "p99_latency_s": 41.833906412124634,
    "mean_tokens_per_s": 0.809103832049434,
    "total_tokens_per_s": 5.663726824346038,
    "min_tokens_per_s": 0.7649297601986677,
    "max_tokens_per_s": 0.8598232092326665,
    "peak_alloc_bytes": 0,
    "peak_reserved_bytes": 0,
    "peak_alloc_gb": 0.0,
    "peak_reserved_gb": 0.0,
    "mean_alloc_bytes": 0.0,
    "mean_reserved_bytes": 0.0
  },
  "timestamp": 1757162383.8509364
}